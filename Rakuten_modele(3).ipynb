{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Rakuten_modele(3).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freezer2019/Rakuten-Paris-Product-Classification/blob/main/Rakuten_modele(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpSDQdgAzOM",
        "outputId": "8b64aa31-07a6-4dc7-87af-3faad934c50f"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEJnN-1PBrV4",
        "outputId": "b9ef2a85-a555-41ca-9c06-b34d0196c925"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import nltk\n",
        "from nltk import WordPunctTokenizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from transformers import CamembertModel, CamembertTokenizer, CamembertConfig\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import torch.nn as nn \n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms, utils\n",
        "import random\n",
        "import cv2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgomrPKmBp8m",
        "outputId": "9e4a3ce1-a1d2-4eb7-85c7-1e2b78e30651"
      },
      "source": [
        "from google.colab import drive,files\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egoFX4t9D2vP",
        "outputId": "ae508951-3f13-46c8-edb0-773ee1c4b31f"
      },
      "source": [
        "!unzip /content/drive/MyDrive/DS2021/Datasets/archive\\(8\\).zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/DS2021/Datasets/archive(8).zip\n",
            "replace X_test_update.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ4BEz1ED3wd"
      },
      "source": [
        "x_train = pd.read_csv(\"/content/X_train_update.csv\")\n",
        "y_train = pd.read_csv(\"/content/Y_train_CVw08PX.csv\")\n",
        "x_test = pd.read_csv(\"/content/X_test_update.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPhsmO0ZEH1S"
      },
      "source": [
        "x_train.rename(columns = {\"Unnamed: 0\": \"Id\"}, inplace = True)\n",
        "y_train.rename(columns = {\"Unnamed: 0\": \"Id\"}, inplace = True)\n",
        "x_test.rename(columns = {\"Unnamed: 0\": \"Id\"}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0qhpi6-lLQO"
      },
      "source": [
        "Helpers function, Classes\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91VfE49sFs0H"
      },
      "source": [
        "class simple_Text_cleaner(BaseEstimator, TransformerMixin):\n",
        "  # add another additional parameter, just for fun, while we are at it\n",
        "    def __init__(self, stopwords,columns,tokenizer=WordPunctTokenizer()): \n",
        "        self.columns = columns\n",
        "        self.stopwords = stopwords\n",
        "        self.tokenizer=tokenizer\n",
        "    def rm_stopwords(self,tokens):\n",
        "        tokens=self.tokenizer.tokenize(tokens)\n",
        "        return [ tk for tk in tokens if  tk not in self.stopwords ]\n",
        "    def text_clean_up(self,s=\"\"):\n",
        "        import re\n",
        "        user_pattern       = '@[^\\s]+'\n",
        "        s=re.sub(user_pattern, \"\", s)\n",
        "        remove = '\"#$%&()*+/:;<=>@[\\\\]^_`{|}~”“'\n",
        "        pattern = r\"[{}]\".format(remove)\n",
        "        s=re.sub(pattern,' ', s) \n",
        "        sequencePattern   = r\"(.)\\1\\1+\"\n",
        "        seqReplacePattern = r\"\\1\\1\"\n",
        "        s = re.sub(sequencePattern, seqReplacePattern, s)\n",
        "        s = re.sub(\"<[^>]*>\",' ', s)\n",
        "        s = re.sub(\"[\\r\\n]+\",' ', s)\n",
        "        s = re.sub(\"http\\S+\",' ', s)\n",
        "        s = re.sub(\"\\$[^>]*\\$\",' ', s)\n",
        "        s = re.sub(\"\\d+\",' ', s)\n",
        "        s = re.sub(\"\\s\\s+\",' ', s)\n",
        "        s.strip()\n",
        "        return s\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[\"image_path\"] = (X_[\"imageid\"].apply(lambda x: str(int(x)))+\"_product_\"+X_[\"productid\"].apply(lambda x: str(int(x)))+\".jpg\").apply(lambda x: \"image_\"+x)\n",
        "        for i in self.columns:\n",
        "            X_[i] = X_[i].apply(lambda x: \" \".join(self.rm_stopwords(self.text_clean_up(x))))\n",
        "        return X_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdT0SN64GIxp"
      },
      "source": [
        "def encode_reviews(tokenizer, model, device, cpu, reviews, max_length,batch):\n",
        "    token_ids = torch.tensor([])\n",
        "    input_ids=torch.tensor([],dtype=torch.long)\n",
        "    attention_mask=torch.tensor([],dtype=torch.long)\n",
        "    h = 0\n",
        "    for i, review in enumerate(reviews):\n",
        "        encoded = encoded_text = tokenizer.encode_plus(\n",
        "                        review,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_length,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "        input_ids=torch.cat((input_ids,encoded_text['input_ids']),dim=0)\n",
        "        attention_mask=torch.cat((attention_mask,encoded_text['attention_mask']),dim=0)\n",
        "        h+=1\n",
        "        if h == batch:\n",
        "            hidden = model(input_ids.to(device),attention_mask=attention_mask.to(device))[2][-2]\n",
        "            token_ids=torch.cat((token_ids,torch.mean(hidden, dim=1).to(cpu)),dim=0)\n",
        "            h=0\n",
        "            input_ids=torch.tensor([],dtype=torch.long)\n",
        "            attention_mask=torch.tensor([],dtype=torch.long)\n",
        "    if len(input_ids) != 0:\n",
        "        hidden = model(input_ids.to(device),attention_mask=attention_mask.to(device))[2][-2]\n",
        "        token_ids=torch.cat((token_ids,torch.mean(hidden, dim=1).to(cpu)),dim=0)\n",
        "        print(token_ids.size())\n",
        "    token_ids=token_ids.numpy()\n",
        "    print(token_ids.shape)\n",
        "    return token_ids\n",
        "\n",
        "class CamembertPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, max_seq_length,column,bs=128):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.cpu=torch.device(\"cpu\")\n",
        "        print(self.device)\n",
        "        self.tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "        self.config = CamembertConfig.from_pretrained(\"camembert-base\", output_hidden_states=True)\n",
        "        self.camembert =CamembertModel.from_pretrained(\"camembert-base\", config=self.config).to(self.device)\n",
        "        for p in self.camembert.parameters():\n",
        "                p.requires_grad_(False)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.column = column\n",
        "        self.camembert.eval()\n",
        "        self.batch=bs\n",
        "    def fit(self, X=None):\n",
        "        return self \n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        # 1. Tokenize\n",
        "        X_encoded = encode_reviews(self.tokenizer,self.camembert,self.device,self.cpu, X[self.column].values, self.max_seq_length,self.batch)\n",
        "        return X_encoded     \n",
        "    \n",
        "    def fit_transform(self, X, y=None):        \n",
        "        return self.transform(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4DmnNcp6KFt"
      },
      "source": [
        "\n",
        "torch.cat((torch.tensor([]),torch.tensor([1,2])),dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1WTwE-WGI7r"
      },
      "source": [
        "class Second_to_last_SentenceEmbedding(nn.Module):\n",
        "    def __init__(self,to_tune):\n",
        "        #super(, self).__init__()\n",
        "        super().__init__()\n",
        "        self.config = CamembertConfig.from_pretrained(\"camembert-base\", output_hidden_states=True)\n",
        "        self.camembert = CamembertModel.from_pretrained(\"camembert-base\", config=self.config)\n",
        "        dense_layer1 = nn.Sequential(nn.Linear(768,256),nn.ReLU(),nn.Dropout(p=0.2))\n",
        "        dense_layer2 = nn.Sequential(nn.Linear(256,100),nn.ReLU(),nn.Dropout(p=0.2))\n",
        "        fc2=nn.Linear(100,27)\n",
        "        self.dense=nn.Sequential(dense_layer1, dense_layer2, fc2)\n",
        "        if not to_tune:\n",
        "            for p in self.camembert.parameters():\n",
        "                p.requires_grad_(False)\n",
        "    def forward(self, input,attention_mask=None):\n",
        "        hidden = self.camembert(input,attention_mask=attention_mask)[2]\n",
        "        token_vecs = hidden[-2]\n",
        "        x = torch.mean(token_vecs,dim=1)\n",
        "        return self.dense(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcZS8g4NGJEJ"
      },
      "source": [
        "class Columns_Selector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,column):\n",
        "        self.column = column\n",
        "    def fit(self, X = None):\n",
        "        return self \n",
        "    def transform(self, X, y=None):\n",
        "        return X[self.column]     \n",
        "    def fit_transform(self, X, y=None):        \n",
        "        return self.transform(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pal4xfSiGJLT"
      },
      "source": [
        "class To_dense(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def fit(self, X = None):\n",
        "        return self \n",
        "    def transform(self, X, y=None):\n",
        "        X = X.toarray()\n",
        "        print(X.shape)\n",
        "        return X \n",
        "    def fit_transform(self, X, y=None):        \n",
        "        return self.transform(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7yq_DWHRIQ"
      },
      "source": [
        "class MultimodalDataset (Dataset):\n",
        "    def __init__(self,tokenizer, input_csv_file, root_dir,max_length=60 , transform=None,Y_csv_file=None):\n",
        "        if type(input_csv_file) == str:\n",
        "            self.input_file = pd.read_csv(input_csv_file)\n",
        "        else:\n",
        "            self.input_file = input_csv_file\n",
        "        self.input_file.rename(columns={\"Unnamed: 0\": \"Id\"}, inplace=True)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform =transform\n",
        "        self.max_length=max_length\n",
        "        self.input_file[\"image_path\"]=(self.input_file[\"imageid\"].apply(lambda x: str(int(x)))+\"_product_\"+self.input_file[\"productid\"].apply(lambda x: str(int(x)))+\".jpg\").apply(lambda x: \"image_\"+x)\n",
        "        if Y_csv_file is not None:\n",
        "            if type(Y_csv_file) == str:\n",
        "                self.output = pd.read_csv(Y_csv_file)\n",
        "                \n",
        "            else:\n",
        "                self.output = Y_csv_file\n",
        "            self.output.rename(columns={\"Unnamed: 0\": \"Id\"}, inplace=True)\n",
        "            self.classes = list(set(self.output[\"prdtypecode\"].values))\n",
        "        else:\n",
        "            self.ouptut = None\n",
        "    def __len__(self):\n",
        "        return len(self.input_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        try:\n",
        "            img_name = os.path.join(self.root_dir,\n",
        "                                    self.input_file[\"image_path\"].iloc[idx])\n",
        "        except:\n",
        "            print(idx)\n",
        "\n",
        "        image = io.imread(img_name)\n",
        "        text = self.input_file[\"designation\"].iloc[idx]\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "        sample = {'image': image, 'input_ids':encoded_text['input_ids'].squeeze(0) ,'attention_mask':encoded_text['attention_mask'].squeeze(0)}\n",
        "        sample['Id']=self.input_file[\"Id\"].iloc[idx]\n",
        "        if self.transform:\n",
        "            sample['image'] = self.transform(sample['image'])\n",
        "        if self.output is None:\n",
        "            return sample\n",
        "        sample[\"label\"]=self.classes.index(self.output[\"prdtypecode\"].loc[self.input_file[\"Id\"].iloc[idx]])\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgApZ_05HZrV"
      },
      "source": [
        "class Microscope:\n",
        "    \"\"\"\n",
        "    Cutting out the edges around the center circle of the image\n",
        "    Imitating a picture, taken through the microscope\n",
        "\n",
        "    Args:\n",
        "        p (float): probability of applying an augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to apply transformation to.\n",
        "\n",
        "        Returns:NumPyNumPy\n",
        "            PIL Image: Image with transformation.\n",
        "        \"\"\"\n",
        "        if random.random() < self.p:\n",
        "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # image placeholder\n",
        "                        (img.shape[0]//2, img.shape[1]//2), # center point of circle\n",
        "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15), # radius\n",
        "                        (0, 0, 0), # color\n",
        "                        -1)\n",
        "\n",
        "            mask = circle - 255\n",
        "            img = np.multiply(img, mask)\n",
        "        \n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(p={self.p})'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZuV956HxZj"
      },
      "source": [
        "class Feature_Extraction(nn.Module):\n",
        "    # deuxieme dimension de l'output de chaque tenseurs a la sortie d'un layer de resnet\n",
        "    resnet_caracteristics=[64,64,64,64,256,512,1024,2048,2048]\n",
        "    pooling_target=[(4,8),(4,8),(4,8),(4,8),(2,4),(2,2),(1,2),(1,1),(1,1)]\n",
        "    embedding_strategy={\"Second_to_last_average\":768,\"Start_token_embedding\":768,\"last_four_embedding_average\":3072}\n",
        "    def __init__(self,resnet_layers=-1,to_tune=False,sentence_embedding=\"Second_to_last_average\"):\n",
        "        #super(, self).__init__()\n",
        "        super().__init__()\n",
        "        self.config = CamembertConfig.from_pretrained(\"camembert-base\", output_hidden_states=True)\n",
        "        self.camembert =CamembertModel.from_pretrained(\"camembert-base\", config=self.config)\n",
        "        self.Resnet = models.resnet50(pretrained=True)\n",
        "        self.Resnet = nn.Sequential(*list(self.Resnet.children())[:resnet_layers])\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(self.pooling_target[resnet_layers-1])\n",
        "        self.flat = nn.Flatten()\n",
        "        self.strategy = sentence_embedding\n",
        "        if sentence_embedding not in self.embedding_strategy:\n",
        "            self.strategy = \"Second_to_last_average\"    \n",
        "        if self.strategy == \"Start_token_embedding\":\n",
        "            to_tune = True\n",
        "        if to_tune == False:\n",
        "            for p in self.camembert.parameters():\n",
        "                p.requires_grad_(False)\n",
        "            for p in self.Resnet.parameters():\n",
        "                p.requires_grad_(False)\n",
        "        self.output_size = [2048, self.embedding_strategy[self.strategy]]\n",
        "    def sentence_embedding(self,hiddens):\n",
        "        # we get the output of the second to last hidden layers and average it over all token\n",
        "        if self.strategy == \"Second_to_last_average\":\n",
        "            return torch.mean(hiddens[-2],dim=1) \n",
        "        # we use the first token embedding  from the ouptut last hidden layers \n",
        "        # fine_tune should be true \n",
        "        elif self.strategy == \"Start_token_embedding\":\n",
        "            return hiddens[-1].permute(1,0,2)[0]\n",
        "        # we use the last four hidden layer average and concatenate them\n",
        "        elif self.strategy == \"last_four_embedding_average\":\n",
        "            x=torch.cat((hiddens[-4], hiddens[-3], hiddens[-2], hiddens[-1]), dim = 2)\n",
        "            return torch.mean(x, dim=1)\n",
        "    def forward(self, input, image, attention_mask=None):\n",
        "        hiddens = self.camembert(input,attention_mask = attention_mask)[2]\n",
        "        embeddings = self.sentence_embedding(hiddens)\n",
        "        x = self.Resnet(image)\n",
        "        h = self.pooling(x)\n",
        "        return embeddings, self.flat(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgcK01jlH6bC"
      },
      "source": [
        "class Multimodal_Dense_model(nn.Module):\n",
        "    def __init__(self,dropout=0.2,resnet_layers=-1,to_tune=False,sentence_embedding=\"Second_to_last_average\"):\n",
        "        #super(, self).__init__()\n",
        "        super().__init__()\n",
        "        self.feature_extractor = Feature_Extraction(resnet_layers=resnet_layers,to_tune=to_tune,sentence_embedding=sentence_embedding)\n",
        "        self.input_size = self.feature_extractor.output_size\n",
        "        self.dense_layer = nn.Sequential(OrderedDict([\n",
        "          ('dense1', nn.Linear(in_features=sum(self.input_size),out_features=768)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('dropout1', nn.Dropout(p=0.2)),\n",
        "          ('dense2', nn.Linear(in_features=768,out_features=256)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('dropout2', nn.Dropout(p=0.2)),\n",
        "          ('dense3', nn.Linear(in_features=256,out_features=64)),\n",
        "          ('relu3', nn.ReLU()),\n",
        "          ('dropout3', nn.Dropout(p=0.2)),\n",
        "          ('output', nn.Linear(64,27))\n",
        "          ]))\n",
        "    def forward(self, input,image,attention_mask=None):\n",
        "        text,image = self.feature_extractor(input=input,image=image,attention_mask=attention_mask)\n",
        "        return self.dense_layer(torch.cat((text,image),dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUaOu1RCIYk6"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        Microscope(p=0.5),\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomResizedCrop(size=384, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(512),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ9fwFN5IBfC"
      },
      "source": [
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "training_set = MultimodalDataset(tokenizer=tokenizer, input_csv_file=\"/content/X_train_update.csv\", root_dir=\"/content/images/images/image_train\",max_length=60 , transform=data_transforms[\"train\"],Y_csv_file=\"/content/Y_train_CVw08PX.csv\")\n",
        "def make_weights_for_balanced_classes(images, nclasses):                                                                            \n",
        "    count = list(images.output[\"prdtypecode\"].value_counts().loc[images.classes])                                    \n",
        "    N = float(sum(count)) \n",
        "    weight_per_class=[0]*nclasses                                                  \n",
        "    for i in range(nclasses):                                                   \n",
        "        weight_per_class[i] = N/float(count[i])                                 \n",
        "    weight = [0] * len(images)                                              \n",
        "    for idx in range(int(N)):    \n",
        "        h=images.classes.index(images.output[\"prdtypecode\"].iloc[idx])                                      \n",
        "        weight[idx] = weight_per_class[h]                                  \n",
        "    return weight\n",
        "weights = make_weights_for_balanced_classes(training_set, len(training_set.classes))                                                                \n",
        "weights = torch.DoubleTensor(weights)                                       \n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))                     \n",
        "                                                                                                                                                                        \n",
        "train_dl = torch.utils.data.DataLoader(training_set, batch_size=16,                              \n",
        "                                                             sampler = sampler, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIv1iRG8Ku6l"
      },
      "source": [
        "Baseline model\n",
        "Tf-idfVectorizer + Logistics Regression (Texte)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dA388wCFyG3"
      },
      "source": [
        "X_train,X_Val,Y_train,Y_Val=train_test_split(x_train, y_train, test_size = 0.2, shuffle = True , random_state = 155)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8cYRrEZCSf"
      },
      "source": [
        "target = Y_train[\"prdtypecode\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNGe90VVlsqd"
      },
      "source": [
        "?LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIkxcZhC8IjR"
      },
      "source": [
        "stop_words = stopwords.words('french')\n",
        "stop_words.extend(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvZL6ieUGH0i"
      },
      "source": [
        "Base_model = Pipeline(steps = [('cleaner', simple_Text_cleaner(stopwords =stop_words, columns = [\"designation\"])),\n",
        "                               ('column_selector', Columns_Selector(column = \"designation\")),\n",
        "                               ('Vectorization', TfidfVectorizer(stop_words = stop_words, max_features = 5000)),\n",
        "                               ('to_dense', To_dense()),\n",
        "                               ('scaler', StandardScaler()),\n",
        "                               ('model', LogisticRegression(multi_class='multinomial',class_weight= \"balanced\"))\n",
        "                           ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fZ7aiHPUib2"
      },
      "source": [
        "Base_model.fit(X_train,target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b5yoJsiWm4r"
      },
      "source": [
        "pred = Base_model.predict(X_Val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jLUb-R9UweH"
      },
      "source": [
        "print(classification_report(pred,Y_Val[\"prdtypecode\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eobnxLcd6r"
      },
      "source": [
        "Bert extraction De feature "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiWBXb1UcacO"
      },
      "source": [
        "Simple_text_model = Pipeline(steps = [('cleaner', simple_Text_cleaner(stopwords =stop_words, columns = [\"designation\"])),\n",
        "                               ('Vectorization', CamembertPreprocessor(max_seq_length = 64, column = \"designation\")),\n",
        "                               ('model', LogisticRegression(multi_class='multinomial',class_weight= \"balanced\"))\n",
        "                           ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cebwAKptA2R"
      },
      "source": [
        "Simple_text_model.fit(X_train,target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iszkVEhlJJ_L"
      },
      "source": [
        "pred = Simple_text_model.predict(X_Val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZCYVA05MHdh"
      },
      "source": [
        "print(classification_report(pred,Y_Val[\"prdtypecode\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "angbHRZdS8Tm"
      },
      "source": [
        "Using Bert give us fewer features than "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Kcu-dlJKo8"
      },
      "source": [
        "Perceptron Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jid6b-c6wwQs"
      },
      "source": [
        "General Train Function-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2BSNuHOwvME"
      },
      "source": [
        "soft_max = nn.LogSoftmax(dim=1)\n",
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(soft_max(out), dim=1) # classe prédite: tensor de taille bs. \n",
        "    return (preds == yb).float().mean()\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    all_loss={\"train\":[],\"val\":[]}\n",
        "    all_acc={\"train\":[],\"val\":[]}\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterattention_maskate over data.\n",
        "            for inputs in dataloaders[phase]:\n",
        "                input_ids = inputs[\"input_ids\"].to(device)\n",
        "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "                labels = inputs[\"label\"].to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(input_ids, attention_mask = attention_mask)\n",
        "                    loss = criterion(outputs, labels , weight  = torch.tensor(weights,dtype = torch.float32).to(device))\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * input_ids.size(0)\n",
        "                running_corrects += accuracy(outputs ,labels)* input_ids.size(0)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataset[phase])\n",
        "            epoch_acc = running_corrects.double() / len(dataset[phase])\n",
        "            all_loss[phase].append(epoch_loss)\n",
        "            all_acc[phase].append(epoch_acc)\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, all_loss, all_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy8NEMHhb0hw"
      },
      "source": [
        "len(dataset[\"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iKTtFwMxzJN"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cpu=torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPr67u-a6yLg"
      },
      "source": [
        "Torch Dataset et DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsNVE9tE63SG"
      },
      "source": [
        "dataset={}\n",
        "dataloaders={}\n",
        "dataset[\"full\"] = MultimodalDataset(tokenizer=tokenizer, input_csv_file=\"/content/X_train_update.csv\", root_dir=\"/content/images/images/image_train\",max_length=60 , transform=data_transforms[\"train\"],Y_csv_file=\"/content/Y_train_CVw08PX.csv\")                     \n",
        "dataloaders[\"full\"] = torch.utils.data.DataLoader(dataset[\"full\"], batch_size=71,shuffle=True, num_workers=4)#balanced dataset\n",
        "\n",
        "dataset[\"train\"]=MultimodalDataset(tokenizer=tokenizer, input_csv_file=X_train, root_dir=\"/content/images/images/image_train\",max_length=60 , transform=data_transforms[\"train\"],Y_csv_file=Y_train)         \n",
        "dataloaders[\"train\"] = torch.utils.data.DataLoader(dataset[\"train\"], batch_size=108,shuffle=True, num_workers=4)#balanced dataset\n",
        "\n",
        "dataset[\"val\"]=MultimodalDataset(tokenizer=tokenizer, input_csv_file=X_Val, root_dir=\"/content/images/images/image_train\",max_length=60 , transform=data_transforms[\"train\"],Y_csv_file=Y_Val)                                                           \n",
        "dataloaders[\"val\"] = torch.utils.data.DataLoader(dataset[\"val\"], batch_size=88,shuffle=True, num_workers=4)#balanced dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTOQTk0zJRpe"
      },
      "source": [
        "**Text** Perceptron\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "On va utiliser la classe Second_to_last_embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvYW-zMEJQwv"
      },
      "source": [
        "Simple_text_model_untuned=Second_to_last_SentenceEmbedding(to_tune=False).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQZrDbw6w-5"
      },
      "source": [
        "optimizer_untuned = optim.SGD(Simple_text_model_untuned.dense.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler_untuned = lr_scheduler.StepLR(optimizer_untuned, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdwykZ6RIBJn"
      },
      "source": [
        "loss_function= F.cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cttnefVqJXA"
      },
      "source": [
        "training the model without tuning the Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkZphNGz_bVN"
      },
      "source": [
        "weights=compute_class_weight(\"balanced\", classes= np.unique(target), y=target)\n",
        "h=np.unique(target)\n",
        "weights_dict={}\n",
        "for i in range(len(h)):\n",
        "    weights_dict[h[i]] = weights[i]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE3DuMYtpF2U"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "Simple_text_model_untuned,untuned_loss,untuned_acc=train_model(Simple_text_model_untuned, \n",
        "                                                   loss_function, optimizer_untuned, exp_lr_scheduler_untuned, num_epochs=5).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAyjSQbLw3_g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8BvD7A1qWcH"
      },
      "source": [
        "Tuning Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sElDEHNvqcDE"
      },
      "source": [
        "Tuning Big Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuvdxT9Gqq2p"
      },
      "source": [
        "model_1 = Multimodal_Dense_model(resnet_layers = 6, to_tune = False ,sentence_embedding = \"last_four_embedding_average\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQIvR51KtNUE"
      },
      "source": [
        "optimizer_1 = optim.SGD(model_1.dense_layer.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler_1 = lr_scheduler.StepLR(optimizer_1, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB2boQQJrzxz"
      },
      "source": [
        "def train_model_multi(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    all_loss={\"train\":[],\"val\":[]}\n",
        "    all_acc={\"train\":[],\"val\":[]}\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterattention_maskate over data.\n",
        "            for inputs in dataloaders[phase]:\n",
        "                image = inputs[\"image\"].to(device)\n",
        "                input_ids = inputs[\"input_ids\"].to(device)\n",
        "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "                labels = inputs[\"label\"].to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(input_ids,image = , attention_mask = attention_mask)\n",
        "                    loss = criterion(outputs, labels, weight=torch.tensor(weights,dtype = torch.float32).to(device))\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * input_ids.size(0)\n",
        "                running_corrects += accuracy(outputs ,labels)*input_ids.size(0)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataset[phase])\n",
        "            epoch_acc = running_corrects.double() /len(dataset[phase])\n",
        "            all_loss[phase].append(epoch_loss)\n",
        "            all_acc[phase].append(epoch_acc)\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, all_loss, all_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICsWDKRmttkd"
      },
      "source": [
        "model_1,loss_1,acc_1 = train_model_multi(model_1, loss_function, optimizer_1, exp_lr_scheduler_1, num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}